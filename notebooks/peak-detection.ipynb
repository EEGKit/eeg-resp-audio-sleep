{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak detection\n",
    "\n",
    "What do we consider to be a peak? Visually, it's the top of the hill, but for a computer\n",
    "we need to find a metic. Thus, let's define the peak as local maxima which respects a\n",
    "predefined list of criteria.\n",
    "[scipy.signal.find_peaks](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html)\n",
    "is perfect for the job as it looks for local maxima which meets a list of criteria.\n",
    "\n",
    "## Criteria\n",
    "\n",
    "### Height\n",
    "\n",
    "The height criterium limits the peak detection to values above a certain `y` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "\n",
    "\n",
    "# create a signal\n",
    "x = np.linspace(0, 6 * np.pi, 1000)\n",
    "x = np.sin(x) + 0.6 * np.sin(2.6 * x)\n",
    "\n",
    "# find peaks with a height of at least 1\n",
    "peaks, _ = find_peaks(x, height=1)\n",
    "\n",
    "# plot\n",
    "f, ax = plt.subplots(1, 1, layout=\"constrained\")\n",
    "ax.plot(x)\n",
    "ax.axhline(y=1, color=\"teal\", linestyle=\"--\")\n",
    "ax.plot(peaks, x[peaks], \"x\", markersize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prominence\n",
    "\n",
    "`scipy` defines the prominence as how much a peak stands out from the surrounding \n",
    "baseline of the signal and is defined as the vertical distance between the peak and its lowest contour line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a signal\n",
    "x = np.linspace(0, 6 * np.pi, 1000)\n",
    "x = np.sin(x) + 0.6 * np.sin(2.6 * x)\n",
    "\n",
    "# find peaks and measure prominence\n",
    "peaks, _ = find_peaks(x)\n",
    "prominences = peak_prominences(x, peaks)[0]\n",
    "\n",
    "# plot\n",
    "contour_heights = x[peaks] - prominences\n",
    "plt.plot(x)\n",
    "plt.plot(peaks, x[peaks], \"x\")\n",
    "plt.vlines(x=peaks, ymin=contour_heights, ymax=x[peaks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respiration signal\n",
    "\n",
    "The respiration signal is:\n",
    "- (1) noisy as all physiological signal which means that we need to filter it before we look for a peak\n",
    "- (2) contains wide peaks with 'flat' tops, which means that depending on the filter applied, the local maxima might slightly move left or right\n",
    "\n",
    "### Local maxima for different filters\n",
    "\n",
    "Let's have a look in the position of the local maxima found by \n",
    "[scipy.signal.find_peaks](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html) for\n",
    "different filters of the same 4 seconds of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mne import set_log_level\n",
    "from mne.io import read_raw_fif\n",
    "from mne_lsl.stream._filters import create_filter\n",
    "from scipy.signal import sosfilt\n",
    "\n",
    "import resp_audio_sleep\n",
    "\n",
    "\n",
    "set_log_level(\"WARNING\")\n",
    "# load data\n",
    "root = Path(resp_audio_sleep.__file__).parent.parent / \"data\"\n",
    "fname = root / \"isochronous-raw.fif\"\n",
    "raw = read_raw_fif(fname, preload=False).pick(\"AUX7\").crop(20, 40).load_data()\n",
    "data = raw.get_data().T  # transpose to match what MNE-LSL prepared the filters for\n",
    "# IIR filters with initial response estimated as a step response steady-state with\n",
    "# scipy.signal.sosfilt_zi\n",
    "filter1 = create_filter(raw.info[\"sfreq\"], None, 10, iir_params=None)\n",
    "filter1[\"zi\"] = np.mean(data, axis=0) * filter1[\"zi_unit\"]\n",
    "filter2 = create_filter(raw.info[\"sfreq\"], None, 40, iir_params=None)\n",
    "filter2[\"zi\"] = np.mean(data, axis=0) * filter2[\"zi_unit\"]\n",
    "data_filter1, _ = sosfilt(filter1[\"sos\"], data, axis=0, zi=filter1[\"zi\"])\n",
    "data_filter2, _ = sosfilt(filter2[\"sos\"], data, axis=0, zi=filter2[\"zi\"])\n",
    "\n",
    "# plot\n",
    "f, ax = plt.subplots(1, 1, layout=\"constrained\")\n",
    "ax.plot(raw.times, data.squeeze(), color=\"blue\", label=\"raw\")\n",
    "ax.plot(raw.times, data_filter1.squeeze(), color=\"teal\", label=\"10 Hz low-pass\")\n",
    "ax.plot(raw.times, data_filter2.squeeze(), color=\"orange\", label=\"40 Hz low-pass\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'strange' start behavior is due to the initial conditions being set to the min of\n",
    "the signal. To ignore this section, let's look for peaks which are above the mean\n",
    "value of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "# find peaks with constrains\n",
    "peaks_raw, _ = find_peaks(data.squeeze(), height=np.mean(data.squeeze()), prominence=50)\n",
    "peaks_filter1, _ = find_peaks(\n",
    "    data_filter1.squeeze(), height=np.mean(data_filter1.squeeze()), prominence=10\n",
    ")\n",
    "peaks_filter2, _ = find_peaks(\n",
    "    data_filter2.squeeze(), height=np.mean(data_filter2.squeeze()), prominence=10\n",
    ")\n",
    "\n",
    "# plot\n",
    "f, ax = plt.subplots(1, 1, layout=\"constrained\")\n",
    "ax.plot(raw.times, data.squeeze(), color=\"blue\", label=\"raw\")\n",
    "ax.plot(raw.times, data_filter1.squeeze(), color=\"teal\", label=\"10 Hz low-pass\")\n",
    "ax.plot(raw.times, data_filter2.squeeze(), color=\"orange\", label=\"40 Hz low-pass\")\n",
    "for peak in peaks_raw:\n",
    "    ax.axvline(raw.times[peak], color=\"blue\", linestyle=\"--\")\n",
    "for peak in peaks_filter1:\n",
    "    ax.axvline(raw.times[peak], color=\"teal\", linestyle=\"--\")\n",
    "for peak in peaks_filter2:\n",
    "    ax.axvline(raw.times[peak], color=\"orange\", linestyle=\"--\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start to see the issue, due to the peak shape, the local maxima is moving a bit based on the processing applied. Let's zoom on the last peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, layout=\"constrained\")\n",
    "ax.plot(raw.times, data.squeeze(), color=\"blue\", label=\"raw\")\n",
    "ax.plot(raw.times, data_filter1.squeeze(), color=\"teal\", label=\"10 Hz low-pass\")\n",
    "ax.plot(raw.times, data_filter2.squeeze(), color=\"orange\", label=\"40 Hz low-pass\")\n",
    "for peak in peaks_raw:\n",
    "    ax.axvline(raw.times[peak], color=\"blue\", linestyle=\"--\")\n",
    "for peak in peaks_filter1:\n",
    "    ax.axvline(raw.times[peak], color=\"teal\", linestyle=\"--\")\n",
    "for peak in peaks_filter2:\n",
    "    ax.axvline(raw.times[peak], color=\"orange\", linestyle=\"--\")\n",
    "ax.legend()\n",
    "# select the last second\n",
    "ax.set_xlim(raw.times[-int(1 * raw.info[\"sfreq\"])], raw.times[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the distance between the 10 Hz low-pass filtered local maxima and the\n",
    "40 Hz low-pass filtered local maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 1000 * (peaks_filter1[-1] - peaks_filter2[-1]) / raw.info[\"sfreq\"]\n",
    "print(  # noqa: T201\n",
    "    f\"Distance between 10 Hz and 40 Hz low-pass signal local maximas: {delay:.1f} ms.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters chosen for the online detector\n",
    "\n",
    "For the online detector, I chose to use 3 filters:\n",
    "- (1) IIR causal butter order 4 notch @ 50 Hz\n",
    "- (2) IIR causal butter order 4 notch @ 100\n",
    "- (3) IIR causal butter order 4 low-pass @ 20 Hz\n",
    "\n",
    "This combination does not distort the phase of the signal too much and thus does not\n",
    "shift the peak compared to its real location.\n",
    "\n",
    "An acausal FIR filter works (no noticeable boundary effect) but is (1) slower and (2) \n",
    "exacerbate the offline replication problem. Thus, I kept the IIR instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.crop(10, 20)\n",
    "raw_filtered = raw.copy()\n",
    "raw_filtered.notch_filter(50, picks=\"AUX7\", method=\"iir\", phase=\"forward\")\n",
    "raw_filtered.notch_filter(100, picks=\"AUX7\", method=\"iir\", phase=\"forward\")\n",
    "raw_filtered.filter(None, 20, picks=\"AUX7\", method=\"iir\", phase=\"forward\")\n",
    "raw.crop(5, None)\n",
    "raw_filtered.crop(5, None)  # time for the filter without initial state to settle\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1, 1, layout=\"constrained\")\n",
    "ax.plot(raw.times, raw.get_data().squeeze(), color=\"gray\", label=\"raw\")\n",
    "ax.plot(raw.times, raw_filtered.get_data().squeeze(), color=\"teal\", label=\"filtered\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online detection and triggering logic\n",
    "\n",
    "Let's now cover the entire online detection logic.\n",
    "\n",
    "## Detector\n",
    "\n",
    "### Circular buffer\n",
    "\n",
    "The detector has a 4 seconds circular buffer that sees new data coming in and old data\n",
    "coming out. When new samples are available, they are retrieved, filtered, and added to\n",
    "the buffer.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"https://mne.tools/mne-lsl/stable/_images/circular-buffer-light.png\" /></div>\n",
    "\n",
    "In practice, the circular buffer is implemented as a `numpy` array ordered from left to\n",
    "right:\n",
    "\n",
    "- on the left, the old samples\n",
    "- on the right, the new samples\n",
    "\n",
    "When `N` new samples are added to the buffer, we roll the buffer by N thus moving the N\n",
    "first sample to the end, and then we replace those last N samples with the N new samples\n",
    "retrieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# buffer of 10 samples: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
    "buffer = np.arange(10)\n",
    "print(\"Buffer:\\t\\t\\t\", buffer)  # noqa: T201\n",
    "new_samples = np.array([10, 11, 12])\n",
    "buffer = np.roll(buffer, -new_samples.size)\n",
    "print(\"Buffer rolled:\\t\\t\", buffer)  # noqa: T201\n",
    "buffer[-new_samples.size :] = new_samples\n",
    "print(\"Buffer updated:\\t\\t\", buffer)  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring and filtering new samples\n",
    "\n",
    "In an online loop, the acquisition of new samples and the update of the circular buffer\n",
    "is coded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code, do not run this cell\n",
    "\n",
    "# construct filter\n",
    "from scipy.signal import sosfilt, sosfilt_zi\n",
    "\n",
    "filter = create_filter(...)  # create second order sections (sos)  # noqa: A001\n",
    "filter[\"zi_unit\"] = sosfilt_zi(filter[\"sos\"])  # create initial conditions\n",
    "filter[\"zi\"] = (\n",
    "    None  # initial conditions for the filter that will be updated in the first iteration of the loop  # noqa: E501\n",
    ")\n",
    "\n",
    "# create buffer\n",
    "import numpy as np  # noqa: E402\n",
    "\n",
    "buffer = np.zeros(...)\n",
    "\n",
    "# online acquisition loop\n",
    "while True:\n",
    "    # query the network for new samples, we might get some or we might get none\n",
    "    new_samples, new_samples_timestamps = inlet.pull_chunk()  # noqa: F821\n",
    "    if new_samples_timestamps.size == 0:\n",
    "        # no new samples, thus we 'continue', i.e. we go back to the beginning of the\n",
    "        # loop and query the network again (without delay) for new samples\n",
    "        continue\n",
    "\n",
    "    # process the new samples, in this case apply the filter. We need to know the filter\n",
    "    # state 'zi', which is either the state of the N-1 iteration, or the initial state\n",
    "    # estimated as the steady-state response of the filter to a step input.\n",
    "    if filter[\"zi\"] is None:\n",
    "        # first iteration, estimate using a step input equal to the mean of the signal\n",
    "        # which is realistic for EEG signal subject to an important DC offset.\n",
    "        filter[\"zi\"] = np.mean(new_samples) * filter[\"zi_unit\"]\n",
    "    # now we have our initial conditions, thus we filter the new samples with those\n",
    "    # initial conditions and we overwrite the initial conditions with the state of the\n",
    "    # filter at the end of the filtering process, preparing the next iteration.\n",
    "    new_samples, filter[\"zi\"] = sosfilt(filter[\"sos\"], new_samples, zi=filter[\"zi\"])\n",
    "\n",
    "    # update the buffer, using the rolling system details previously.\n",
    "    buffer = np.roll(buffer, -new_samples.size)\n",
    "    buffer[-new_samples.size :] = new_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop contains all of the acquisition logic used in `mne_lsl.stream.StreamLSL`.\n",
    "\n",
    "### Detecting new peak and delivering sounds\n",
    "\n",
    "Now that we have a filtered buffer, we look for peaks. It boils down to extending the\n",
    "previous loop to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code, do not run this cell\n",
    "\n",
    "# construct filter\n",
    "from scipy.signal import sosfilt, sosfilt_zi\n",
    "\n",
    "filter = create_filter(...)  # create second order sections (sos)  # noqa: A001\n",
    "filter[\"zi_unit\"] = sosfilt_zi(filter[\"sos\"])  # create initial conditions\n",
    "filter[\"zi\"] = (\n",
    "    None  # initial conditions for the filter that will be updated in the first iteration of the loop  # noqa: E501\n",
    ")\n",
    "\n",
    "# create buffer\n",
    "import numpy as np  # noqa: E402\n",
    "\n",
    "buffer = np.zeros(...)\n",
    "timestamps_buffer = np.zeros(...)\n",
    "\n",
    "# online acquisition loop\n",
    "while True:\n",
    "    # query the network for new samples, we might get some or we might get none\n",
    "    new_samples, new_samples_timestamps = inlet.pull_chunk()  # noqa: F821\n",
    "    if new_samples_timestamps.size == 0:\n",
    "        # no new samples, thus we 'continue', i.e. we go back to the beginning of the\n",
    "        # loop and query the network again (without delay) for new samples\n",
    "        continue\n",
    "\n",
    "    # process the new samples, in this case apply the filter. We need to know the filter\n",
    "    # state 'zi', which is either the state of the N-1 iteration, or the initial state\n",
    "    # estimated as the steady-state response of the filter to a step input.\n",
    "    if filter[\"zi\"] is None:\n",
    "        # first iteration, estimate using a step input equal to the mean of the signal\n",
    "        # which is realistic for EEG signal subject to an important DC offset.\n",
    "        filter[\"zi\"] = np.mean(new_samples) * filter[\"zi_unit\"]\n",
    "    # now we have our initial conditions, thus we filter the new samples with those\n",
    "    # initial conditions and we overwrite the initial conditions with the state of the\n",
    "    # filter at the end of the filtering process, preparing the next iteration.\n",
    "    new_samples, filter[\"zi\"] = sosfilt(filter[\"sos\"], new_samples, zi=filter[\"zi\"])\n",
    "\n",
    "    # update the buffer, using the rolling system details previously.\n",
    "    buffer = np.roll(buffer, -new_samples.size)\n",
    "    buffer[-new_samples.size :] = new_samples\n",
    "    timestamps_buffer = np.roll(timestamps_buffer, -new_samples_timestamps.size)\n",
    "    timestamps_buffer[-new_samples_timestamps.size :] = new_samples_timestamps\n",
    "\n",
    "    # detrend the signal\n",
    "    z = np.polyfit(timestamps_buffer, buffer, 1)\n",
    "    data = buffer - (z[0] * timestamps_buffer + z[1])\n",
    "\n",
    "    # detect all the peaks in the buffer, this function tells you at which sample in the\n",
    "    # buffer a peak is present, e.g. peaks = np.array([100, 1800, 3500]) means that I\n",
    "    # have 3 peaks at the index 100, 1800, and 3500 of the buffer.\n",
    "    peaks, _ = find_peaks(data, height=..., prominence=...)\n",
    "\n",
    "    # triage the peaks to figure out if any of those peaks is new, because either it was\n",
    "    # already detected and processed in the past, or it was detected for the first time\n",
    "    # and is thus a new, very recent, peak.\n",
    "    # if new_peak is None, the peak was already returned in the past. If the peak was\n",
    "    # not returned in the past, returns the index of the new peak in the buffer, e.g.\n",
    "    # new_peak = 1000 means that the new peak is at the index 1000 of the buffer.\n",
    "    new_peak = triage_peaks(peaks)  # noqa\n",
    "\n",
    "    if new_peak is None:\n",
    "        # we don't have any new peak to play with, let's go back to the beginning of the\n",
    "        # loop and query the network for new samples.\n",
    "        continue\n",
    "\n",
    "    # process the new peak, first let's figure out how late we are:\n",
    "    now = local_clock()  # current time on the same timescale as the timestamps buffer\n",
    "    late_by = now - timestamps_buffer[new_peak]\n",
    "\n",
    "    # now let's plan the sound in the future (I'm a bit simplifying here because we\n",
    "    # have 2 different clock base to handle, LSL and PsychtoolBox, but the idea is to\n",
    "    # plan the sound 250 ms after the peak by correcting based on 'late_by').\n",
    "    sound.play(when=timestamps_buffer[new_peak] + 0.25)\n",
    "    # now we wait until the sound is going to be played, again we correct by how 'late'\n",
    "    # we were im the detection.\n",
    "    sleep(...)\n",
    "    trigger.signal(...)  # and now we deliver the trigger, simultaneously with the sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's the general structure of the online loop used here for both synchronous conditions. Now, the problem we observe between online detection and offline replication, is that the filtered buffer on which `find_peaks` is run differ! Exactly as shown in the beginning of the notebook where 2 different filters yields 2 slightly different waveforms with different local maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
